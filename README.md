# Point-Cloud
Paper
##CLIP
[PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning](https://arxiv.org/abs/2211.11682) [CVPR2022; [Github](https://github.com/yangyangyang127/PointCLIP_V2)]
[CLIP2: Contrastive Language-Image-Point Pretraining from Real-World Point Cloud Data](https://arxiv.org/abs/2303.12417) [CVPR2023; [Github]]
## Few-shot


[Few-shot Class-incremental Learning for 3D Point Cloud Objects](https://doi.org/10.48550/arXiv.2205.15225) [ECCV2022; [Github](https://github.com/townim-faisal/FSCIL-3D)]

[CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP](https://arxiv.org/pdf/2301.04926v1.pdf) [CVPR2023; ]

[GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds](https://arxiv.org/pdf/2212.03010.pdf) [CVPR2023; [Github](https://github.com/Nightmare-n/GD-MAE)]

[PointCLIP: Point Cloud Understanding by CLIP](https://arxiv.org/abs/2112.02413) [CVPR2022; [Github](https://github.com/ZrrSkywalker/PointCLIP)]

